{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Window Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OVER and PARTITION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From <a href=\"https://www.postgresql.org/docs/9.1/tutorial-window.html\">PostreSQL tutorial</a>:\n",
    "<quote><p>\"A window function performs a calculation across a set of table rows that are somehow related to the current row. This is comparable to the type of calculation that can be done with an aggregate function. But unlike regular aggregate functions, use of a window function does not cause rows to become grouped into a single output row — the rows retain their separate identities. Behind the scenes, the window function is able to access more than just the current row of the query result.</p>\n",
    "\n",
    "<p>Here is an example that shows how to compare each employee's salary with the average salary in his or her department:\"</p></quote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>SELECT depname, empno, salary, avg(salary) OVER (PARTITION BY depname) FROM empsalary;</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a results for each employee (empno) in addition to his individual salary we will have the average salary for his department (depname) in the column empsalary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can’t use window functions and standard aggregations in the same query. More specifically, you can’t include window functions in a GROUP BY clause.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code calculates sum for each day so that we can compare standard amount per one order to the amount per the entire day.  \n",
    "\n",
    "<code>SELECT standard_amt_usd,\n",
    "       SUM(standard_amt_usd) OVER (ORDER BY occurred_at) AS running_total\n",
    "FROM orders</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate total amounts for each year:\n",
    "\n",
    "<code>SELECT standard_amt_usd,\n",
    "       DATE_TRUNC('year', occurred_at) as year,\n",
    "       SUM(standard_amt_usd) OVER (PARTITION BY DATE_TRUNC('year', occurred_at) ORDER BY occurred_at) AS running_total\n",
    "FROM orders\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANK() and ROW_NUMBER()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From <a href=\"https://stackoverflow.com/questions/7747327/sql-rank-versus-row-number\">StackOverflow</a>  \n",
    "\n",
    "<b>ROW_NUMBER</b> : Returns a unique number for each row starting with 1. For rows that have duplicate values,numbers are arbitarily assigned.\n",
    "\n",
    "<b>Rank</b> : Assigns a unique number for each row starting with 1,except for rows that have duplicate values,in which case the same ranking is assigned and a gap appears in the sequence for each duplicate ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example 1\n",
    "The code does the following: \n",
    "for each account we order by total and assign rank according to that. So for each account-total pair their will be a ranking according to the value in the 'total' column. This ranking will be saved in total_rank column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>SELECT id,\n",
    "       account_id,\n",
    "       total,\n",
    "       RANK() OVER (PARTITION BY account_id ORDER BY total DESC) AS total_rank\n",
    "FROM orders\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALIASES\n",
    "\n",
    "##### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>SELECT id,\n",
    "       account_id,\n",
    "       DATE_TRUNC('year',occurred_at) AS year,\n",
    "       DENSE_RANK() OVER account_year_window AS dense_rank,\n",
    "       total_amt_usd,\n",
    "       SUM(total_amt_usd) OVER account_year_window AS sum_total_amt_usd,\n",
    "       COUNT(total_amt_usd) OVER account_year_window AS count_total_amt_usd,\n",
    "       AVG(total_amt_usd) OVER account_year_window AS avg_total_amt_usd,\n",
    "       MIN(total_amt_usd) OVER account_year_window AS min_total_amt_usd,\n",
    "       MAX(total_amt_usd) OVER account_year_window AS max_total_amt_usd\n",
    "FROM orders\n",
    "WINDOW account_year_window as (PARTITION BY account_id ORDER BY DATE_TRUNC('year',occurred_at))\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAG and LEAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAG pulls from previous rows, LEAD pulls from following rows. Simply put, it allows to shift the column down or up so that we can compare them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code> SELECT occurred_at,\n",
    "       total_amt_usd,\n",
    "       LEAD(total_amt_usd) OVER (ORDER BY occurred_at) AS lead,\n",
    "       LEAD(total_amt_usd) OVER (ORDER BY occurred_at) - total_amt_usd AS lead_difference\n",
    "FROM (\n",
    "SELECT occurred_at,\n",
    "       SUM(total_amt_usd) AS total_amt_usd\n",
    "  FROM orders \n",
    " GROUP BY 1\n",
    ") sub\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUANTILE and PERCENTILE   \n",
    "The syntax is NTILE(*# of buckets*). In this case, ORDER BY determines which column to use to determine the quartiles (or whatever number of ‘tiles you specify). Number of buckets is an \"integer ranging from 1 to the argument value, dividing the partition as equally as possible\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>SELECT account_id, occurred_at,\n",
    "standard_qty,\n",
    "NTILE(4) OVER (PARTITION BY account_id ORDER BY standard_qty) as quartile\n",
    "FROM orders\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>SELECT account_id, occurred_at,\n",
    "standard_qty,\n",
    "NTILE(2) OVER (PARTITION BY account_id ORDER BY gloss_qty) as gloss_half\n",
    "FROM orders</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced JOINS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symmetric Difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get symmetic difference - records that are present only in one of the tables - either in A or in B. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>SELECT column_name(s)\n",
    "FROM Table_A\n",
    "FULL OUTER JOIN Table_B ON Table_A.column_name = Table_B.column_name;    \n",
    "WHERE Table_A.column_name IS NULL OR Table_B.column_name IS NULL\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self JOINS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each order in table o1 we find the orders that happend in that account AFTER that order. We also limit the orders to 28-day interval: only orders that wer made no later than 28 days after the order in table o1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>SELECT o1.id AS o1_id,\n",
    "       o1.account_id AS o1_account_id,\n",
    "       o1.occurred_at AS o1_occurred_at,\n",
    "       o2.id AS o2_id,\n",
    "       o2.account_id AS o2_account_id,\n",
    "       o2.occurred_at AS o2_occurred_at\n",
    "  FROM orders o1\n",
    " LEFT JOIN orders o2\n",
    "   ON o1.account_id = o2.account_id\n",
    "  AND o2.occurred_at > o1.occurred_at\n",
    "  AND o2.occurred_at <= o1.occurred_at + INTERVAL '28 days'\n",
    "ORDER BY o1.account_id, o1.occurred_at\n",
    "</code>                                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNION removes duplicates. If we want to retain them, we should use UNION ALL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queary Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things that affect speed: \n",
    "- Table size  \n",
    "- Joins  \n",
    "- Aggregations  \n",
    "\n",
    "And also (but these are not controllable):  \n",
    "- Other users running queries concurrently on the database  \n",
    "- Database software and optimization (e.g., Postgres is optimized differently than Redshift)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tips to improve performance: \n",
    "- Filter the data set\n",
    "- Write and test query on a subset \n",
    "- Aggregations happen before LIMIT, so LIMIT doesn't help\n",
    "- For aggregations: do filtering in a subquery, and only then do the aggregation\n",
    "- For testing query, reduce the size of a subset in a subquery\n",
    "- Reduce table sizes before joining them\n",
    "- Do aggregation in a subquery and then do the join. This way we will reduce the cost of join (since it will be performed on a smaller dataset. WARNING: do check the logic!!! \n",
    "- use EXPLAIN before the query to check the execution plan for the query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
